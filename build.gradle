import com.modrinth.minotaur.TaskModrinthUpload
import com.modrinth.minotaur.dependencies.ModDependency
import com.modrinth.minotaur.dependencies.VersionDependency
import groovy.json.JsonOutput
import groovy.json.JsonSlurper
import net.darkhax.curseforgegradle.TaskPublishCurseForge
import net.darkhax.curseforgegradle.UploadArtifact
import net.minecraftforge.gradle.common.util.RunConfig
import net.minecraftforge.gradle.userdev.tasks.RenameJarInPlace

import java.util.function.Consumer

plugins {
    id 'org.ajoberstar.grgit.service' version '5.2.0'
    id 'net.darkhax.curseforgegradle' version '1.1.16'
    id "com.modrinth.minotaur" version "2.+"
    id 'java'
    id 'eclipse'
    id 'idea'
    id 'maven-publish'
    id 'net.neoforged.gradle' version '[6.0.18,6.2)'
    id 'org.parchmentmc.librarian.forgegradle' version '1.+'
}

tasks.named('wrapper', Wrapper).configure {
    //Define wrapper values here so as to not have to always do so when updating gradlew.properties
    gradleVersion = '8.4'
    distributionType = Wrapper.DistributionType.ALL
}

defaultTasks 'build'

idea {
    module {
        //Exclude directories from being managed
        for (String excludeDirName in ["run", "out", "logs", "gradle"]) {
            excludeDirs.add(new File(projectDir, excludeDirName))
        }
    }
}

group = group_id
def basicVersion = "${mod_version}." + (System.env.BUILD_NUMBER ?: 000)
version = "${minecraft_version}-${basicVersion}"
archivesBaseName = "Numina"

ext {
    versionProperties = [
            "version": project.version,
            "minecraft_version": minecraft_version_range,
            "neo_version": neo_version_range,
            "loader_version": loader_version_range,
            "jei_version": jei_version_range]
    jsonPatterns = ["**/*.json", "**/*.mcmeta"]
    secondaryModules = ['powersuits', 'mpsrecipecreator', 'mpswhatever']
    extraTypes = ['datagen']
}

sourceSets {
    main {
        resources {
            include '**/**'
            //Add the generated main module resources
            srcDirs += ['src/datagen/generated/numina']
            //But exclude the cache of the generated data from what gets built
            exclude '.cache'
        }
    }
}

configurations {
    datagenNonMod
}

//Add all extra source sets that the main sourceSet should have
setupExtraSourceSets(sourceSets.main)

configurations {
    //Make sure all our sub source set stuff extends the proper base methods so that
    // they can see all the dependencies we have in dependencies including forge
    extendConfigurations(implementation)
    extendConfigurations(compileOnly)
    extendConfigurations(runtimeOnly)
}

//Create sourceSets and configurations for each of the additional modules in src/$name and adds a reference to
// the corresponding data gen's resource directory excluding the cache. It also adds the main numina module to
// the dependencies of the source set we are setting up, and sets up all extra source sets that are
// based on the primary added source set
for (String name : secondaryModules) {
    def sourceSet = sourceSets.create(name)
    sourceSet.resources {
        //Add the generated module resources
        srcDirs += ["src/datagen/generated/${name}"]
        println("sourceDirs for ${name}")
        srcDirs.forEach {
            x -> println(x)
        }

        //But exclude the cache of the generated data from what gets built
        exclude '.cache'
    }
    sourceSet.compileClasspath += sourceSets.main.output
    //Create all secondary sourceSets for this module
    setupExtraSourceSets(sourceSet)
}

//Setup the UPDATE_SOURCESET property in case we are doing any remappings
project.ext."UPDATE_SOURCESETS" = project.sourceSets.collect { it.name }.join(';')

def setupExtraSourceSets(SourceSet base) {
    //Setup and extend configurations for alternate modules. First by making the implementation, compileOnly, runtimeOnly equivalents
    // for those modules extend the main ones
    def baseImplementation = project.configurations.maybeCreate(base.getTaskName(null, "implementation"))
    def baseCompileOnly = project.configurations.maybeCreate(base.getTaskName(null, "compileOnly"))
    def baseRuntimeOnly = project.configurations.maybeCreate(base.getTaskName(null, "runtimeOnly"))
    if (base != project.sourceSets.main) {
        // If this is a secondary module then make the base tasks extend the builtin ones
        baseImplementation.extendsFrom(project.configurations.getByName("implementation"))
        baseCompileOnly.extendsFrom(project.configurations.getByName("compileOnly"))
        baseRuntimeOnly.extendsFrom(project.configurations.getByName("runtimeOnly"))
    }
    //And then setup and have all the extra sourceSets have their configurations extend the ones for the base module so that they can
    // properly access the dependency
    for (String extraType : extraTypes) {
        //Setup a source set in extraType/$name
        def extraSourceSet = setupExtraSourceSet(base, extraType)
        //And then setup the configurations for it
        def implExtends = [baseImplementation]
        if (extraType == 'datagen'){
            implExtends.add(project.configurations.getByName("datagenNonMod"))
        }
        project.configurations.maybeCreate(extraSourceSet.getTaskName(null, "implementation")).extendsFrom(*implExtends)
        project.configurations.maybeCreate(extraSourceSet.getTaskName(null, "compileOnly")).extendsFrom(baseCompileOnly)
        project.configurations.maybeCreate(extraSourceSet.getTaskName(null, "runtimeOnly")).extendsFrom(baseRuntimeOnly)
    }
}

SourceSet setupExtraSourceSet(SourceSet baseSourceSet, String extra) {
    def name = baseSourceSet.getName()
    def extraSourceSet = sourceSets.create(baseSourceSet.getTaskName(extra, null))
    extraSourceSet.java.srcDirs = ["src/${extra}/${name}/java"]
    //Resources folder for if we have anything get created by our annotation processors or in the case of game tests, for any nbt presets
    extraSourceSet.resources.srcDirs = ["src/${extra}/${name}/resources"]
    extraSourceSet.compileClasspath += project.sourceSets.main.output
    if (baseSourceSet != project.sourceSets.main) {
        //If the base sourceSet is main it already is the extra source set and has a reference to the base one from before this if statement
        extraSourceSet.compileClasspath += getExtraSourceSet(project.sourceSets.main, extra).output
        extraSourceSet.compileClasspath += baseSourceSet.output
    }
    return extraSourceSet
}

static void extendConfigurations(Configuration base, Configuration... configurations) {
    for (def configuration : configurations) {
        configuration.extendsFrom(base)
    }
}

SourceSet getExtraSourceSet(String base, String name) {
    return getExtraSourceSet(project.sourceSets.getByName(base), name)
}

SourceSet getExtraSourceSet(SourceSet base, String name) {
    return project.sourceSets.getByName(base.getTaskName(name, null))
}

setupTasks(sourceSets.main)
for (String name : secondaryModules) {
    setupTasks(sourceSets.getByName(name))
}

def setupTasks(SourceSet sourceSet) {
    def output = sourceSet.name
    def compileTask = tasks.named(sourceSet.getCompileJavaTaskName(), JavaCompile)
    def replaceResourceTask = tasks.register(sourceSet.getTaskName("replace", "resources"), Copy, {
        setGroup("replace resources")
        outputs.upToDateWhen { false }
        def modsToml = copySpec {
            from(sourceSet.resources) {
                include "META-INF/mods.toml"
                expand versionProperties
            }
        }
        //Copy it into the build dir
        with(modsToml)
        into "$buildDir/resources/${output}/"
        //If IntelliJ's output dir exists, copy it there as well
        def intellijPath = sourceSet == project.sourceSets.main ? "production" : output
        if (new File("$rootDir/out/${intellijPath}/resources/").exists()) {
            copy {
                with(modsToml)
                into "$rootDir/out/${intellijPath}/resources/"
            }
        }
        //If Eclipse's output dir exists, copy it there as well
        if (new File("$rootDir/bin/${output}/").exists()) {
            copy {
                with(modsToml)
                into "$rootDir/bin/${output}/"
            }
        }
    })
    //Set the various variables/settings for the different process resources tasks
    tasks.named(sourceSet.getProcessResourcesTaskName(), ProcessResources).configure {
        setGroup("process resources")
        duplicatesStrategy(DuplicatesStrategy.FAIL)
        exclude('META-INF/mods.toml')
        from("${projectDir}") { include 'logo.png' }
        //Depend on the compile task so that we can map the computer methods as needed
        dependsOn(compileTask)
        finalizedBy(replaceResourceTask)
        doLast {
            fileTree(dir: getOutputs().getFiles().getAsPath(), includes: jsonPatterns).each {
                File file -> file.setText(JsonOutput.toJson(new JsonSlurper().parse(file)))
            }
        }
    }
    tasks.named(sourceSet.getCompileJavaTaskName(), JavaCompile).configure { setGroup("compile") }
    for (String extraType : extraTypes) {
        def extraSourceSet = getExtraSourceSet(sourceSet, extraType)
        tasks.named(extraSourceSet.getProcessResourcesTaskName(), ProcessResources).configure {
            setGroup("process resources")
            dependsOn(compileTask)
        }
        tasks.named(extraSourceSet.getCompileJavaTaskName(), JavaCompile).configure { setGroup("compile") }
    }
    //Make the various classes tasks depend on the corresponding replaceResources tasks in addition to the default processResources tasks they depend on
    tasks.named(sourceSet.getClassesTaskName()).configure { dependsOn(replaceResourceTask) }
    //Configure specific compile tasks to have the proper annotation processor info
    compileTask.configure {
        setGroup("compile")
    }
}

java {
    toolchain {
        languageVersion.set(JavaLanguageVersion.of("${java_version}"))
        vendor.set(JvmVendorSpec.JETBRAINS)
    }
}

//nb this exists here so that IDEA can resolve `project`
def datagenExtraClasspath = {
    def paths = new HashSet<String>()
    project.configurations.datagenNonMod.copyRecursive().resolve()
            .collect { it.absolutePath.toString() }
            .findAll { (!it.contains("datafixerupper")) }//avoid adding datafixerupper twice as modlauncher will die
            .each { path -> paths.add(path) }
    return paths.join(File.pathSeparator)
}

minecraft {
    if (mappings_channel == "parchment_previous") {
        mappings channel: 'parchment', version: "${previous_minecraft_version}-${mappings_version}"
    } else {
        mappings channel: "${mappings_channel}", version: "${mappings_version}"
    }

    accessTransformers.from(
            file('src/main/resources/META-INF/accesstransformer.cfg'),
            file('src/powersuits/resources/META-INF/accesstransformer.cfg'),
            file('src/mpsrecipecreator/resources/META-INF/accesstransformer.cfg'))

    runs {
        client {
            setupRunConfig(it, "run/client")
            //The below if statements are to add args to your gradle.properties file in user home
            // (DO NOT add them directly to the gradle.properties file for this project)
            // Setting the below properties allows use of your normal Minecraft account in the
            // dev environment including having your skin load. Each property also has a comment
            // explaining what information to set the value to/format it expects
            // One thing to note is because of the caching that goes on, after changing these
            // variables, you need to refresh the project and rerun genIntellijRuns/genEclipseRuns
            if (project.hasProperty('mc_uuid')) {
                //Your uuid without any dashes in the middle
                args '--uuid', project.getProperty('mc_uuid')
            }
            if (project.hasProperty('mc_username')) {
                //Your username/display name, this is the name that shows up in chat
                // Note: This is not your email, even if you have a Mojang account
                args '--username', project.getProperty('mc_username')
            }
            if (project.hasProperty('mc_accessToken')) {
                //Your access token, you can find it in your '.minecraft/launcher_accounts.json' file
                args '--accessToken', project.getProperty('mc_accessToken')
            }
        }
        server { setupRunConfig(it, "run/server") }
        data {
            setupRunConfig(it, "run/data")
            environment 'target', 'fmluserdevdata'
            args '--all', '--output', file('src/datagen/generated/'),
                    '--mod', 'numina', '--existing', file('src/main/resources/')

            mods.named("numina").configure {
                source((SourceSet) sourceSets.datagenMain)
            }
            for (String name : secondaryModules) {


                def modName = "${name}"


                def extra = getExtraSourceSet(name, 'datagen')
                mods.named(modName).configure {
                    source(extra)
                }
                println("modName: ${modName}, name: ${name}")


                args '--mod', modName, '--existing', file("src/${name}/resources/")
            }

            project.afterEvaluate {
                //After the project has been evaluated so our dependencies has been populated,
                // add all the extra non-mod files to runData's minecraft classpath so that they can be
                // access from the game module layer at runtime
                lazyToken("minecraft_classpath", datagenExtraClasspath)
            }
        }
    }
}

def setupRunConfig(RunConfig runConfig, String directory) {
    runConfig.workingDirectory(file(directory))
    //This fixes Mixin application problems from other mods because their refMaps are SRG-based, but we're in a MCP env
    runConfig.property 'mixin.env.remapRefMap', 'true'
    runConfig.property 'mixin.env.refMapRemappingFile', "${projectDir}/build/createSrgToMcp/output.srg"

    if (project.hasProperty('forge_force_ansi')) {
        //Force ansi if declared as a gradle variable, as the auto detection doesn't detect IntelliJ properly
        // or eclipse's plugin that adds support for ansi escape in console
        runConfig.jvmArg("-Dterminal.ansi=${project.getProperty('forge_force_ansi')}")
    }

    runConfig.mods.register("numina").configure {
        sources((SourceSet[]) [sourceSets.main])
    }
    for (String name : secondaryModules) {
        def base = sourceSets.getByName(name)
        def extra = null
        runConfig.mods.register("${name}").configure {
            source(base)
        }
    }

    //if the selected toolchain is a JBR, enable DCEVM
    if(project.javaToolchains.launcherFor(java.toolchain).map{it.metadata.vendor }.getOrElse("").contains("JetBrains")) {
        runConfig.jvmArg("-XX:+AllowEnhancedClassRedefinition")
    }
}

void exclusiveRepo(RepositoryHandler handler, String url, String... groups) {
    exclusiveRepo(handler, url, filter -> {
        for (def group : groups) {
            filter.includeGroup(group)
        }
    })
}

//Note: This cannot be static so that fg.repository can be properly accessed
@SuppressWarnings('GrMethodMayBeStatic')
void exclusiveRepo(RepositoryHandler handler, String url, Consumer<InclusiveRepositoryContentDescriptor> filterSetup) {
    handler.exclusiveContent {
        it.forRepositories(handler.maven {
            setUrl(url)
        }, fg.repository)//Add FG's repo so we make sure we are able to then find the mapped deps
        it.filter { f -> filterSetup.accept(f) }
    }
}

repositories { RepositoryHandler handler ->
    exclusiveRepo(handler, 'https://maven.blamejared.com', filter -> {
        filter.includeGroupByRegex 'com\\.blamejared.*'
        filter.includeGroup 'mezz.jei'
        filter.includeGroup 'org.openzen.zencode'
    })
    exclusiveRepo(handler, 'https://maven.theillusivec4.top/', 'top.theillusivec4.curios')
    exclusiveRepo(handler, 'https://maven.tterrag.com/', 'team.chisel.ctm')
    exclusiveRepo(handler, 'https://squiddev.cc/maven/', 'cc.tweaked', 'org.squiddev')
    exclusiveRepo(handler, 'https://dogforce-games.com/maven/', 'dev.gigaherz.jsonthings')
    exclusiveRepo(handler, 'https://maven2.bai.lol', 'lol.bai', 'mcp.mobius.waila')//WTHIT
    exclusiveRepo(handler, 'https://www.cursemaven.com', 'curse.maven')
    exclusiveRepo(handler, 'https://modmaven.dev/', 'appeng', 'mcjty.theoneprobe')
    exclusiveRepo(handler, 'https://maven.thiakil.com', 'com.thiakil')
    exclusiveRepo(handler, 'https://maven.parchmentmc.org/', 'org.parchmentmc.data')
}

dependencies {
    minecraft "net.neoforged:forge:${minecraft_version}-${neo_version}"

    compileOnly fg.deobf("mezz.jei:jei-${minecraft_version}-common-api:${jei_version}")
    compileOnly fg.deobf("mezz.jei:jei-${minecraft_version}-forge-api:${jei_version}")
    runtimeOnly fg.deobf("mezz.jei:jei-${minecraft_version}-forge:${jei_version}")

    //TODO - 1.19: Re-enable once https://github.com/Chisel-Team/ConnectedTexturesMod/pull/204 is merged
    //runtimeOnly fg.deobf("team.chisel.ctm:CTM:${minecraft_version}-${ctm_version}")

    //TODO: Remove having to specify these as non transitive once https://github.com/McJtyMods/TheOneProbe/issues/548 is fixed
//    compileOnly fg.deobf("mcjty.theoneprobe:theoneprobe:${top_version}:api") {
//        transitive = false
//    }
//    runtimeOnly fg.deobf("mcjty.theoneprobe:theoneprobe:${top_version}") {
//        transitive = false
//    }
//    compileOnly fg.deobf("curse.maven:female-gender-forge-481655:${wildfire_gender_mod_id}")
}

def getManifestAttributes(String title) {
    return [
            "Specification-Title"     : title,
            "Specification-Vendor"    : "MachineMuse",
            "Specification-Version"   : "${project.version}",
            "Implementation-Title"    : title,
            "Implementation-Version"  : "${project.version}",
            "Implementation-Vendor"   : "MachineMuse",
            "Implementation-Timestamp": new Date().format("yyyy-MM-dd'T'HH:mm:ssZ"),
            "Automatic-Module-Name": title.toLowerCase(Locale.ROOT)
    ]
}

tasks.named('jar', Jar).configure {
    duplicatesStrategy(DuplicatesStrategy.FAIL)
    from([sourceSets.main.output])
    manifest.attributes(getManifestAttributes("Numina"))
}

def secondaryJar(SourceSet sourceSet, String title) {
    return tasks.register(sourceSet.getJarTaskName(), Jar, {
        duplicatesStrategy(DuplicatesStrategy.FAIL)
        archiveClassifier.set(sourceSet.name)
        from sourceSet.output
        if (!title.isEmpty()) {
            archiveFileName.set("${title}-${project.version}.jar")
        }
        manifest.attributes(getManifestAttributes(title.isEmpty() ? "Numina" : title))
    })
}

def powersuitsJar = secondaryJar(sourceSets.powersuits, 'ModularPowersuits')
def mpsrecipecreatorJar = secondaryJar(sourceSets.mpsrecipecreator, 'MPSRecipeCreator')
def mpswhateverJar = secondaryJar(sourceSets.mpswhatever, 'MPSWhatever')

clean {
    //TODO: Try to come up with a slightly better solution to this that deletes more,
    // for example make it calculate the current hash and only leave that or only do
    // this if clean build is being ran. We also ideally would have it remove some of
    // the data from our generated folder, but for now this will do given jenkins runs
    // a clean build because we need to make sure it doesn't fail
    def filteredDelete = new HashSet<>()
    for (def toDelete : getDelete()) {
        for (def f : file(toDelete).listFiles()) {
            if (f.getName() != "fg_cache") {
                filteredDelete.add(f)
            }
        }
    }
    setDelete(filteredDelete)
}

tasks.withType(JavaCompile).configureEach({
    options.encoding = 'UTF-8'
    options.compilerArgs.addAll(["-Xmaxerrs", "100000"])
})

tasks.withType(Javadoc).configureEach({
    options.tags = [
            'apiNote:a:<em>API Note:</em>',
            'implSpec:a:<em>Implementation Requirements:</em>',
            'implNote:a:<em>Implementation Note:</em>'
    ]
})

artifacts {
    archives jar
    archives powersuitsJar
    archives mpsrecipecreatorJar
    archives mpswhateverJar
}

//createReobf(sourceSets.api)
for (String name : secondaryModules) {
    createReobf(sourceSets.getByName(name))
}

def createReobf(SourceSet sourceSet) {
    def reobfTask = createReobf(sourceSet.getJarTaskName())
    reobfTask.configure { libraries.from(sourceSet.compileClasspath) }
    tasks.named(sourceSet.getJarTaskName()).configure(task -> task.finalizedBy(reobfTask))
    return reobfTask
}

def createReobf(String name) {
    def reobfExtension = (NamedDomainObjectContainer<RenameJarInPlace>) extensions.getByName("reobf")
    return reobfExtension.register(name)
}

afterEvaluate {
    tasks.named('jar', Jar).configure { finalizedBy(tasks.named('reobfJar', RenameJarInPlace)) }
}

//Minimize/optimize all png files, requires optipng on the PATH
// Credits: BrainStone
void minimizePNGFile(File file) {
    long size = file.length()
    exec {
        executable "optipng"
        args "-q", "-o7", "-zm1-9", "-strip", "all", file
    }
    long newSize = file.length()
    if (newSize < size) {
        System.out.format("Reduced File size of %s from %d bytes to %d bytes (reduced by %.2f%%)\n",
                file, size, newSize, ((double) (size - newSize)) / ((double) size) * 100.0)
    }
}

tasks.register('optimizePng').configure {
    doLast {
        def pngPatterns = ["**/*.png"]
        //Ensure the logo is minimized (we add this file to each jar)
        minimizePNGFile(file("${projectDir}/logo.png"))
        //Minimize any PNGs in the source sets
        def sourceSets = [sourceSets.main, sourceSets.powersuits, sourceSets.mpsrecipecreator, sourceSets.mpswhatever]
        for (def sourceSet : sourceSets) {
            for (dir in sourceSet.resources.srcDirs) {
                fileTree(dir: dir, includes: pngPatterns).each { minimizePNGFile(it) }
            }
        }
    }
}

tasks.withType(GenerateModuleMetadata).configureEach {
    //Disable Gradle 7 module metadata generation as it does not play nicely with FG
    enabled = false
}

def resolvedChangelog = null

//closure to generate the changelog once, and only when needed by CurseGradle or Modrinth
def changeLogResolver = { ->
    if (resolvedChangelog != null) {
        println "Using cached changelog"
        return resolvedChangelog
    }
    def generatedChangelog = "Unable to generate changelog :("
    def currentCommit = System.getenv("GIT_COMMIT")
    def prevCommit = System.getenv("GIT_PREVIOUS_SUCCESSFUL_COMMIT") ?: System.getenv("GIT_PREVIOUS_COMMIT")

    if (currentCommit != null && prevCommit != null) {
        generatedChangelog = ""
        //Use the service to avoid eagerly instantiating the grgit instance, and only do so when we actually need it
        // for usage in generating the changelog for either CF or Modrinth
        grgitService.service.get().grgit.log {
            range(prevCommit, currentCommit)
        }.reverse().each { commit ->
            //Use full message rather than short message to get any new lines, and trim it so that any trailing new lines
            // get removed so that we don't end up with extra spaces
            String message = commit.fullMessage.trim()
            if (!message.startsWith("Merge branch") && !message.startsWith("Merge pull request") && !message.contains("[no-changelog]")) {
                //Ignore Merges and PR Merges
                message = message.replaceAll("#(\\d+)", { match ->//turn issues/prs into links (github currently supports prs being linked as issues)
                    return "<a href=\"https://github.com/lehjr/MachineMusePowersuits/issues/${match[1]}\">${match[0]}</a>"
                }).replaceAll("\\n", "<br>&emsp;")//convert new lines that are part of a commit message into actual new lines and a tab
                if (generatedChangelog != "") {
                    //If this isn't the first commit prepend an extra newline
                    generatedChangelog += "<br>"
                }
                generatedChangelog += "<a href=\"https://github.com/lehjr/MachineMusePowersuits/commit/${commit.id}\">${commit.getAbbreviatedId()}</a> - ${message}"
            }
        }
        println "Changelog generated"
    }

    def releaseNotesFile = project.file("docs/release_${mod_version}.html")
    if (releaseNotesFile.exists()) {
        //Add any version specific changelog stuff
        def releaseNotes = releaseNotesFile.getText()
        generatedChangelog = "$releaseNotes<br> $generatedChangelog"
    }

    if (curse_release_type == "alpha") {
        //Add a warning at the top about what an alpha build means
        generatedChangelog = "Warning: ModularPowersuits is currently in alpha, and is not recommended for widespread use in modpacks. There are likely to be game breaking bugs, " +
                "and updating from one alpha to the next may cause various issues. While we will try to not have this happen/keep it to a minimum make sure " +
                "to make backups." + "<br> $generatedChangelog"
    }
    resolvedChangelog = generatedChangelog
    return generatedChangelog
}

tasks.register('outputChangelog') {
    doLast {
        project.file("build/changelog.html").text = changeLogResolver.call()
    }
}

def mainCfUpload, powersuitsCfUpload, mpswhateverCfUpload, mpsrecipecreatprCfUpload;

if (System.getenv("CURSEFORGE_KEY") != null || project.hasProperty('curseforgeKey')) {
    println "Enabling Curseforge config"
    tasks.register("curseforge", TaskPublishCurseForge, { task ->
        setGroup("publishing")
        setDescription("Upload Numina to CurseForge")

        apiToken = System.getenv("CURSEFORGE_KEY") ?: project.findProperty("curseforgeKey")

        def changelog = changeLogResolver.call()

        //Main Numina Project
        mainCfUpload = task.upload(235440, jar) { main ->
            setGenericCurseArtifactData(main, changelog)
            //Include the API jar as a secondary file to the main file
            //Add optional deps
            addOptional(
                    'scannable',
                    'applied-energistics-2',
                    'jei'
            )
        }

        //Secondary modules/projects
        powersuitsCfUpload = uploadSecondaryCurseProject(task, 235442, changelog, powersuitsJar)
//        mpsrecipecreatorCfUpload = uploadSecondaryCurseProject(task, 0, changelog, mpsrecipecreatorJar)
//        mpswhateverCfUpload = uploadSecondaryCurseProject(task, 0, changelog, mpswhateverJar)

        doLast {
            println("https://www.curseforge.com/minecraft/mc-mods/numina/files/${mainCfUpload.curseFileId}")
            println("https://www.curseforge.com/minecraft/mc-mods/modular-powersuits/files/${powersuitsCfUpload.curseFileId}")
//            println("https://www.curseforge.com/minecraft/mc-mods/mpswhatever/files/${mpswhateverCfUpload.curseFileId}")
//            println("https://www.curseforge.com/minecraft/mc-mods/mpsrecipecreator/files/${mpsrecipecreatorCfUpload.curseFileId}")
        }
    })
}

void setGenericCurseArtifactData(UploadArtifact artifact, String changelog) {
    artifact.changelog = changelog
    artifact.changelogType = 'html'
    artifact.releaseType = "${release_type}"
    //Add that we support forge for now as we currently support both Forge and NeoForge. NeoForge is detected automatically from the gradle plugin
    artifact.addModLoader("NeoForged")
}

UploadArtifact uploadSecondaryCurseProject(TaskPublishCurseForge task, long projectId, String changelog, TaskProvider<Jar> sourceSetJar) {
    return task.upload(projectId, sourceSetJar) { artifact ->
        setGenericCurseArtifactData(artifact, changelog)
        addRequirement('numina')
    }
}

if (System.getenv("MODRINTH_TOKEN") != null || project.hasProperty('modrinthToken')) {
    println "Enabling Modrinth config"
    def powersuitsModrinth = createSecondaryModrinthUpload("powersuits", "mBO0J08x", powersuitsJar)
//    def mpsrecipecreatorModrinth = createSecondaryModrinthUpload("mpsrecipecreator", "", mpsrecipecreatorJar)
//    def mpswhateverModrinth = createSecondaryModrinthUpload("mpswhatever", "", mpswhateverJar)
    tasks.named('modrinth').configure {
        dependsOn(jar)
        finalizedBy(powersuitsModrinth, mpsrecipecreatorModrinth, mpswhateverModrinth)
    }

    modrinth {
        if (System.getenv("MODRINTH_TOKEN") == null) {
            //Defaults to MODRINTH_TOKEN so we only have to check for a token via gradle properties if there isn't a system property
            getToken().value((String) project.findProperty("modrinthToken"))
        } else {
            token = System.getenv("MODRINTH_TOKEN")
        }
        projectId = "MRNzikxs"
        //Use the full "basic" version number rather than just mod version number so that if multiple releases end up happening due to bugs
        // then we don't run into conflicts in uploading
        //Note: The versionName is set to the versionNumber automatically
        versionNumber = "${basicVersion}"
        versionType = "${release_type}"
        changelog = changeLogResolver.call()
        uploadFile = jar
        //Add that we support forge for now as we currently support both Forge and NeoForge
        // Note: Once we no longer support forge we can just remove the line as NeoForge will be able to be detected automatically
        // Currently we can't as Minotaur only detects loaders if none are set
        loaders.addAll("forge", "neoforge")

        //Note: Can't use nested dependency configuration as we have no way to clear it for the secondary uploads
        getDependencies().value([
                new ModDependency("XxWD5pD3", "optional"),//AE2
        ])
    }

}

def createSecondaryModrinthUpload(String output, String targetProjectId, TaskProvider<Jar> sourceSetJar) {
    return tasks.register("${output}Modrinth", TaskModrinthUpload, {
        setGroup("publishing")
        setDescription("Upload Numina ${output} to Modrinth")
        dependsOn(tasks.named("modrinth"), sourceSetJar)
        doFirst {
            //Run in do first to change the configured extension values before it starts applying
            modrinth {
                projectId = targetProjectId
                uploadFile = sourceSetJar.get()
                //Clear additional upload files as this is a modification of what things are set to from before
                getAdditionalFiles().empty()
                //Mark that the addon requires the build of Numina that we just uploaded (and override it to clear all optional dependencies)
                if (tasks.modrinth.newVersion == null || tasks.modrinth.newVersion.getId() == null) {
                    //If we failed to find the upload version just set it to Numina in general
                    getDependencies().value([new ModDependency("MRNzikxs", "required")])
                } else {
                    getDependencies().value([new VersionDependency(tasks.modrinth.newVersion.getId(), "required")])
                }
            }
            println "Updated Modrinth extension"
        }
    })
}